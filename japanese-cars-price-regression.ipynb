{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b081c30-f219-4a1e-9c44-181108db3b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, SpatialDropout1D, BatchNormalization, Embedding, Flatten, Activation, Input, concatenate\n",
    "from tensorflow.keras.layers import SimpleRNN, GRU, LSTM, Bidirectional, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam, Adadelta, SGD, Adagrad, RMSprop\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error\n",
    "from datetime import datetime\n",
    "\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c012b6b-536f-4ede-b831-45855e7e1f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1308aa-7fef-42c6-8318-78e4c6f0fca3",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb829ac-6e6f-40e3-8016-0d008e799d9a",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00fab207-68df-428b-a9e8-7766a1eab97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://storage.yandexcloud.net/academy.ai/japan_cars_dataset.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.to_csv('japan_cars_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e57a6777-756a-479d-8f56-b72ba13e01cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>price</th>\n",
       "      <th>mark</th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine_capacity</th>\n",
       "      <th>transmission</th>\n",
       "      <th>drive</th>\n",
       "      <th>hand_drive</th>\n",
       "      <th>fuel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>nissan</td>\n",
       "      <td>march</td>\n",
       "      <td>2003</td>\n",
       "      <td>80000</td>\n",
       "      <td>1240</td>\n",
       "      <td>at</td>\n",
       "      <td>2wd</td>\n",
       "      <td>rhd</td>\n",
       "      <td>gasoline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>nissan</td>\n",
       "      <td>march</td>\n",
       "      <td>2010</td>\n",
       "      <td>53000</td>\n",
       "      <td>1200</td>\n",
       "      <td>at</td>\n",
       "      <td>2wd</td>\n",
       "      <td>rhd</td>\n",
       "      <td>gasoline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>165</td>\n",
       "      <td>nissan</td>\n",
       "      <td>lafesta</td>\n",
       "      <td>2005</td>\n",
       "      <td>47690</td>\n",
       "      <td>2000</td>\n",
       "      <td>at</td>\n",
       "      <td>2wd</td>\n",
       "      <td>rhd</td>\n",
       "      <td>gasoline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>190</td>\n",
       "      <td>toyota</td>\n",
       "      <td>avensis</td>\n",
       "      <td>2008</td>\n",
       "      <td>130661</td>\n",
       "      <td>1990</td>\n",
       "      <td>at</td>\n",
       "      <td>2wd</td>\n",
       "      <td>rhd</td>\n",
       "      <td>gasoline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>190</td>\n",
       "      <td>daihatsu</td>\n",
       "      <td>mira</td>\n",
       "      <td>2006</td>\n",
       "      <td>66300</td>\n",
       "      <td>660</td>\n",
       "      <td>at</td>\n",
       "      <td>2wd</td>\n",
       "      <td>rhd</td>\n",
       "      <td>gasoline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>190</td>\n",
       "      <td>daihatsu</td>\n",
       "      <td>mira</td>\n",
       "      <td>2004</td>\n",
       "      <td>81400</td>\n",
       "      <td>660</td>\n",
       "      <td>at</td>\n",
       "      <td>2wd</td>\n",
       "      <td>rhd</td>\n",
       "      <td>gasoline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>220</td>\n",
       "      <td>nissan</td>\n",
       "      <td>march</td>\n",
       "      <td>2010</td>\n",
       "      <td>117000</td>\n",
       "      <td>1200</td>\n",
       "      <td>at</td>\n",
       "      <td>2wd</td>\n",
       "      <td>rhd</td>\n",
       "      <td>gasoline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>230</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>passat</td>\n",
       "      <td>2008</td>\n",
       "      <td>127763</td>\n",
       "      <td>3190</td>\n",
       "      <td>at</td>\n",
       "      <td>4wd</td>\n",
       "      <td>rhd</td>\n",
       "      <td>gasoline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>275</td>\n",
       "      <td>mazda</td>\n",
       "      <td>bongo van</td>\n",
       "      <td>2010</td>\n",
       "      <td>178218</td>\n",
       "      <td>1800</td>\n",
       "      <td>mt</td>\n",
       "      <td>2wd</td>\n",
       "      <td>rhd</td>\n",
       "      <td>gasoline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>283</td>\n",
       "      <td>honda</td>\n",
       "      <td>step wgn</td>\n",
       "      <td>2005</td>\n",
       "      <td>121655</td>\n",
       "      <td>2000</td>\n",
       "      <td>at</td>\n",
       "      <td>2wd</td>\n",
       "      <td>rhd</td>\n",
       "      <td>gasoline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  price        mark      model  year  mileage  engine_capacity  \\\n",
       "0           0     80      nissan      march  2003    80000             1240   \n",
       "1           1    110      nissan      march  2010    53000             1200   \n",
       "2           2    165      nissan    lafesta  2005    47690             2000   \n",
       "3           3    190      toyota    avensis  2008   130661             1990   \n",
       "4           4    190    daihatsu       mira  2006    66300              660   \n",
       "5           5    190    daihatsu       mira  2004    81400              660   \n",
       "6           8    220      nissan      march  2010   117000             1200   \n",
       "7           9    230  volkswagen     passat  2008   127763             3190   \n",
       "8          10    275       mazda  bongo van  2010   178218             1800   \n",
       "9          11    283       honda   step wgn  2005   121655             2000   \n",
       "\n",
       "  transmission drive hand_drive      fuel  \n",
       "0           at   2wd        rhd  gasoline  \n",
       "1           at   2wd        rhd  gasoline  \n",
       "2           at   2wd        rhd  gasoline  \n",
       "3           at   2wd        rhd  gasoline  \n",
       "4           at   2wd        rhd  gasoline  \n",
       "5           at   2wd        rhd  gasoline  \n",
       "6           at   2wd        rhd  gasoline  \n",
       "7           at   4wd        rhd  gasoline  \n",
       "8           mt   2wd        rhd  gasoline  \n",
       "9           at   2wd        rhd  gasoline  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4d8cf3f-aef6-4354-b6d6-61fea41cd720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>mark</th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine_capacity</th>\n",
       "      <th>transmission</th>\n",
       "      <th>drive</th>\n",
       "      <th>hand_drive</th>\n",
       "      <th>fuel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>nissan</td>\n",
       "      <td>march</td>\n",
       "      <td>2003</td>\n",
       "      <td>80000</td>\n",
       "      <td>1240</td>\n",
       "      <td>at</td>\n",
       "      <td>2wd</td>\n",
       "      <td>rhd</td>\n",
       "      <td>gasoline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110</td>\n",
       "      <td>nissan</td>\n",
       "      <td>march</td>\n",
       "      <td>2010</td>\n",
       "      <td>53000</td>\n",
       "      <td>1200</td>\n",
       "      <td>at</td>\n",
       "      <td>2wd</td>\n",
       "      <td>rhd</td>\n",
       "      <td>gasoline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>165</td>\n",
       "      <td>nissan</td>\n",
       "      <td>lafesta</td>\n",
       "      <td>2005</td>\n",
       "      <td>47690</td>\n",
       "      <td>2000</td>\n",
       "      <td>at</td>\n",
       "      <td>2wd</td>\n",
       "      <td>rhd</td>\n",
       "      <td>gasoline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>190</td>\n",
       "      <td>toyota</td>\n",
       "      <td>avensis</td>\n",
       "      <td>2008</td>\n",
       "      <td>130661</td>\n",
       "      <td>1990</td>\n",
       "      <td>at</td>\n",
       "      <td>2wd</td>\n",
       "      <td>rhd</td>\n",
       "      <td>gasoline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>190</td>\n",
       "      <td>daihatsu</td>\n",
       "      <td>mira</td>\n",
       "      <td>2006</td>\n",
       "      <td>66300</td>\n",
       "      <td>660</td>\n",
       "      <td>at</td>\n",
       "      <td>2wd</td>\n",
       "      <td>rhd</td>\n",
       "      <td>gasoline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price      mark    model  year  mileage  engine_capacity transmission  \\\n",
       "0     80    nissan    march  2003    80000             1240           at   \n",
       "1    110    nissan    march  2010    53000             1200           at   \n",
       "2    165    nissan  lafesta  2005    47690             2000           at   \n",
       "3    190    toyota  avensis  2008   130661             1990           at   \n",
       "4    190  daihatsu     mira  2006    66300              660           at   \n",
       "\n",
       "  drive hand_drive      fuel  \n",
       "0   2wd        rhd  gasoline  \n",
       "1   2wd        rhd  gasoline  \n",
       "2   2wd        rhd  gasoline  \n",
       "3   2wd        rhd  gasoline  \n",
       "4   2wd        rhd  gasoline  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['Unnamed: 0'], inplace=True, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfa320c1-1ff3-475d-9923-92e6e9ab6776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2318 entries, 0 to 2317\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   price            2318 non-null   int64 \n",
      " 1   mark             2318 non-null   object\n",
      " 2   model            2318 non-null   object\n",
      " 3   year             2318 non-null   int64 \n",
      " 4   mileage          2318 non-null   int64 \n",
      " 5   engine_capacity  2318 non-null   int64 \n",
      " 6   transmission     2318 non-null   object\n",
      " 7   drive            2318 non-null   object\n",
      " 8   hand_drive       2318 non-null   object\n",
      " 9   fuel             2318 non-null   object\n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 181.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c755df68-11d0-41f2-99f7-041992f35583",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fa96e5d-d1d0-43c3-b0b9-85693f50577a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine_capacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2318.000000</td>\n",
       "      <td>2318.000000</td>\n",
       "      <td>2318.000000</td>\n",
       "      <td>2318.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>971.522433</td>\n",
       "      <td>2005.972390</td>\n",
       "      <td>100013.194996</td>\n",
       "      <td>1507.010785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>288.673112</td>\n",
       "      <td>3.698863</td>\n",
       "      <td>52512.478883</td>\n",
       "      <td>549.585170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>1979.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>776.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>67000.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>94000.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1213.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>124000.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1400.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>790000.000000</td>\n",
       "      <td>12340.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             price         year        mileage  engine_capacity\n",
       "count  2318.000000  2318.000000    2318.000000      2318.000000\n",
       "mean    971.522433  2005.972390  100013.194996      1507.010785\n",
       "std     288.673112     3.698863   52512.478883       549.585170\n",
       "min      80.000000  1979.000000    2000.000000         9.000000\n",
       "25%     776.000000  2004.000000   67000.000000      1300.000000\n",
       "50%    1000.000000  2006.000000   94000.000000      1490.000000\n",
       "75%    1213.000000  2009.000000  124000.000000      1800.000000\n",
       "max    1400.000000  2015.000000  790000.000000     12340.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['price', 'year', 'mileage', 'engine_capacity']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee3acb91-1e2c-4b0b-8da7-09d86e465b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['car_age'] = 2015 - df['year']  # Возраст авто\n",
    "df['mileage_per_year'] = df['mileage'] / (df['car_age'] + 1)\n",
    "\n",
    "df = df[df['year'] >= 1990]\n",
    "df = df[df['mileage'] <= 300000]\n",
    "df = df[(df['engine_capacity'] >= 600) & (df['engine_capacity'] <= 4000)]\n",
    "df = df[(df['price'] >= 200) & (df['price'] <= 1250)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a6ffe80-92da-407b-91df-3c7ad6742215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine_capacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1841.000000</td>\n",
       "      <td>1841.000000</td>\n",
       "      <td>1841.000000</td>\n",
       "      <td>1841.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>885.060293</td>\n",
       "      <td>2006.108637</td>\n",
       "      <td>98011.152091</td>\n",
       "      <td>1483.568169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>249.098905</td>\n",
       "      <td>3.589861</td>\n",
       "      <td>44805.922027</td>\n",
       "      <td>485.352738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>220.000000</td>\n",
       "      <td>1990.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>650.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>700.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>66000.000000</td>\n",
       "      <td>1290.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>920.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>93000.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1100.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>122676.000000</td>\n",
       "      <td>1780.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1250.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>296910.000000</td>\n",
       "      <td>3690.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             price         year        mileage  engine_capacity\n",
       "count  1841.000000  1841.000000    1841.000000      1841.000000\n",
       "mean    885.060293  2006.108637   98011.152091      1483.568169\n",
       "std     249.098905     3.589861   44805.922027       485.352738\n",
       "min     220.000000  1990.000000    2000.000000       650.000000\n",
       "25%     700.000000  2004.000000   66000.000000      1290.000000\n",
       "50%     920.000000  2006.000000   93000.000000      1490.000000\n",
       "75%    1100.000000  2009.000000  122676.000000      1780.000000\n",
       "max    1250.000000  2015.000000  296910.000000      3690.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['price', 'year', 'mileage', 'engine_capacity']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa20b467-32b0-4c3f-8434-40b612555f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1841 entries, 6 to 1857\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   price             1841 non-null   int64  \n",
      " 1   mark              1841 non-null   object \n",
      " 2   model             1841 non-null   object \n",
      " 3   year              1841 non-null   int64  \n",
      " 4   mileage           1841 non-null   int64  \n",
      " 5   engine_capacity   1841 non-null   int64  \n",
      " 6   transmission      1841 non-null   object \n",
      " 7   drive             1841 non-null   object \n",
      " 8   hand_drive        1841 non-null   object \n",
      " 9   fuel              1841 non-null   object \n",
      " 10  car_age           1841 non-null   int64  \n",
      " 11  mileage_per_year  1841 non-null   float64\n",
      "dtypes: float64(1), int64(5), object(6)\n",
      "memory usage: 187.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3324f995-5c74-4b45-b942-0c3e6a558c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['mark', 'model', 'transmission', 'drive', 'hand_drive', 'fuel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c26fecb-75c9-497e-b7e4-2fb191e5050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_counts = df['model'].value_counts()\n",
    "df['model'] = df['model'].where(model_counts[df['model']].values >= 10, 'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae1f56-312c-4e6b-9342-9c4fd2ad86ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "609cf789-51f2-4605-8079-a92731659946",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['mark', 'model', 'transmission', 'drive', 'hand_drive', 'fuel']\n",
    "df_encoded = pd.get_dummies(df, columns=cat_features, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5513d44-0dd3-45ed-918c-23dca922b9fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90a34086-192f-4bf2-baa2-3dd4c54e8c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['year', 'mileage', 'engine_capacity', 'car_age', 'mileage_per_year']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "079c8c7c-34d0-4f84-b937-dd97573328df",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_encoded[num_features] = scaler.fit_transform(df_encoded[num_features])\n",
    "\n",
    "df_encoded['price_log'] = np.log1p(df_encoded['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527d2dfa-c843-43aa-bba3-7bb5ddcfac22",
   "metadata": {},
   "source": [
    "## Train/Val/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e42a72e6-5331-4972-8c14-8537515deb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoded.drop(columns=['price', 'price_log'])\n",
    "y = df_encoded['price_log']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e398ccd-2e51-462c-9f59-6dad37cf8951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1288, 69) (276, 69) (277, 69)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8d9166-64ac-454b-a4e3-59bcdd996659",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6d4376-0714-4426-875c-fb6269830aa0",
   "metadata": {},
   "source": [
    "## Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "772a078f-bdfb-4040-b2d1-8090ca03d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input((X_train.shape[1],))\n",
    "\n",
    "x = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01))(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Dense(16, activation='relu')(x)\n",
    "\n",
    "output = Dense(1, activation='linear')(x)\n",
    "model = Model(input_layer, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a6e5d2e-08ee-46b8-b294-aabcacda2e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4554134c-441d-4bce-972c-3785077370c2",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c9f432e-5737-4fb7-984b-d754e0c36f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=80,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=25,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c3f13a-7286-4b7a-9c28-b0e28fa6111d",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24300727-be7f-41a2-ba46-1ba516208d8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 34.4313 - mae: 5.6164 - val_loss: 37.5286 - val_mae: 6.0321 - learning_rate: 0.0010\n",
      "Epoch 2/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 19.4531 - mae: 4.0140 - val_loss: 27.2402 - val_mae: 5.0989 - learning_rate: 0.0010\n",
      "Epoch 3/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10.4270 - mae: 2.6998 - val_loss: 16.8354 - val_mae: 3.9353 - learning_rate: 0.0010\n",
      "Epoch 4/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.0550 - mae: 1.8902 - val_loss: 9.3552 - val_mae: 2.8518 - learning_rate: 0.0010\n",
      "Epoch 5/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.2901 - mae: 1.4995 - val_loss: 5.3368 - val_mae: 2.0476 - learning_rate: 0.0010\n",
      "Epoch 6/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.5500 - mae: 1.3407 - val_loss: 3.4275 - val_mae: 1.5209 - learning_rate: 0.0010\n",
      "Epoch 7/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.2783 - mae: 1.2521 - val_loss: 2.5331 - val_mae: 1.2217 - learning_rate: 0.0010\n",
      "Epoch 8/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.9781 - mae: 1.1773 - val_loss: 2.0073 - val_mae: 0.9871 - learning_rate: 0.0010\n",
      "Epoch 9/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.8300 - mae: 1.1251 - val_loss: 1.7100 - val_mae: 0.8429 - learning_rate: 0.0010\n",
      "Epoch 10/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.7658 - mae: 1.1104 - val_loss: 1.4235 - val_mae: 0.6775 - learning_rate: 0.0010\n",
      "Epoch 11/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.5204 - mae: 1.0401 - val_loss: 1.3032 - val_mae: 0.6040 - learning_rate: 0.0010\n",
      "Epoch 12/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.4738 - mae: 1.0450 - val_loss: 1.3409 - val_mae: 0.6529 - learning_rate: 0.0010\n",
      "Epoch 13/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2849 - mae: 0.9666 - val_loss: 1.1921 - val_mae: 0.5446 - learning_rate: 0.0010\n",
      "Epoch 14/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2385 - mae: 0.9659 - val_loss: 1.1362 - val_mae: 0.5115 - learning_rate: 0.0010\n",
      "Epoch 15/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2112 - mae: 0.9669 - val_loss: 1.1916 - val_mae: 0.5586 - learning_rate: 0.0010\n",
      "Epoch 16/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1396 - mae: 0.9475 - val_loss: 1.1008 - val_mae: 0.5024 - learning_rate: 0.0010\n",
      "Epoch 17/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1353 - mae: 0.9544 - val_loss: 1.0622 - val_mae: 0.4793 - learning_rate: 0.0010\n",
      "Epoch 18/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0486 - mae: 0.9196 - val_loss: 1.0710 - val_mae: 0.4937 - learning_rate: 0.0010\n",
      "Epoch 19/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9625 - mae: 0.8915 - val_loss: 1.0798 - val_mae: 0.5116 - learning_rate: 0.0010\n",
      "Epoch 20/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.9290 - mae: 0.8810 - val_loss: 1.0567 - val_mae: 0.4963 - learning_rate: 0.0010\n",
      "Epoch 21/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8436 - mae: 0.8554 - val_loss: 1.0313 - val_mae: 0.4769 - learning_rate: 0.0010\n",
      "Epoch 22/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8666 - mae: 0.8619 - val_loss: 1.0440 - val_mae: 0.5023 - learning_rate: 0.0010\n",
      "Epoch 23/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8902 - mae: 0.8913 - val_loss: 1.0273 - val_mae: 0.4989 - learning_rate: 0.0010\n",
      "Epoch 24/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8244 - mae: 0.8521 - val_loss: 1.0303 - val_mae: 0.5135 - learning_rate: 0.0010\n",
      "Epoch 25/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8145 - mae: 0.8474 - val_loss: 1.0094 - val_mae: 0.5058 - learning_rate: 0.0010\n",
      "Epoch 26/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7209 - mae: 0.8122 - val_loss: 1.0033 - val_mae: 0.5131 - learning_rate: 0.0010\n",
      "Epoch 27/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7424 - mae: 0.8372 - val_loss: 0.9643 - val_mae: 0.4786 - learning_rate: 0.0010\n",
      "Epoch 28/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6787 - mae: 0.8154 - val_loss: 0.9480 - val_mae: 0.4716 - learning_rate: 0.0010\n",
      "Epoch 29/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6149 - mae: 0.7890 - val_loss: 0.9450 - val_mae: 0.4813 - learning_rate: 0.0010\n",
      "Epoch 30/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5632 - mae: 0.7813 - val_loss: 0.9095 - val_mae: 0.4669 - learning_rate: 0.0010\n",
      "Epoch 31/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6999 - mae: 0.8292 - val_loss: 0.9666 - val_mae: 0.5133 - learning_rate: 0.0010\n",
      "Epoch 32/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5107 - mae: 0.7402 - val_loss: 0.9237 - val_mae: 0.4860 - learning_rate: 0.0010\n",
      "Epoch 33/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5232 - mae: 0.7733 - val_loss: 0.8996 - val_mae: 0.4775 - learning_rate: 0.0010\n",
      "Epoch 34/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5268 - mae: 0.7795 - val_loss: 0.8900 - val_mae: 0.4731 - learning_rate: 0.0010\n",
      "Epoch 35/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5180 - mae: 0.7694 - val_loss: 0.8876 - val_mae: 0.4748 - learning_rate: 0.0010\n",
      "Epoch 36/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4533 - mae: 0.7652 - val_loss: 0.8233 - val_mae: 0.4354 - learning_rate: 0.0010\n",
      "Epoch 37/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4769 - mae: 0.7664 - val_loss: 0.8837 - val_mae: 0.4991 - learning_rate: 0.0010\n",
      "Epoch 38/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4085 - mae: 0.7477 - val_loss: 0.8293 - val_mae: 0.4573 - learning_rate: 0.0010\n",
      "Epoch 39/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3418 - mae: 0.7205 - val_loss: 0.8175 - val_mae: 0.4560 - learning_rate: 0.0010\n",
      "Epoch 40/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3196 - mae: 0.7051 - val_loss: 0.8429 - val_mae: 0.4840 - learning_rate: 0.0010\n",
      "Epoch 41/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3391 - mae: 0.7234 - val_loss: 0.8041 - val_mae: 0.4611 - learning_rate: 0.0010\n",
      "Epoch 42/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3085 - mae: 0.7274 - val_loss: 0.7644 - val_mae: 0.4340 - learning_rate: 0.0010\n",
      "Epoch 43/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3205 - mae: 0.7297 - val_loss: 0.7908 - val_mae: 0.4661 - learning_rate: 0.0010\n",
      "Epoch 44/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2888 - mae: 0.7206 - val_loss: 0.7824 - val_mae: 0.4662 - learning_rate: 0.0010\n",
      "Epoch 45/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2238 - mae: 0.6883 - val_loss: 0.7401 - val_mae: 0.4382 - learning_rate: 0.0010\n",
      "Epoch 46/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2367 - mae: 0.7037 - val_loss: 0.7898 - val_mae: 0.4953 - learning_rate: 0.0010\n",
      "Epoch 47/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1709 - mae: 0.6795 - val_loss: 0.7476 - val_mae: 0.4605 - learning_rate: 0.0010\n",
      "Epoch 48/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1499 - mae: 0.6782 - val_loss: 0.7049 - val_mae: 0.4345 - learning_rate: 0.0010\n",
      "Epoch 49/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1529 - mae: 0.6756 - val_loss: 0.7322 - val_mae: 0.4662 - learning_rate: 0.0010\n",
      "Epoch 50/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1470 - mae: 0.6688 - val_loss: 0.7112 - val_mae: 0.4548 - learning_rate: 0.0010\n",
      "Epoch 51/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0833 - mae: 0.6517 - val_loss: 0.6799 - val_mae: 0.4318 - learning_rate: 0.0010\n",
      "Epoch 52/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0198 - mae: 0.6150 - val_loss: 0.6831 - val_mae: 0.4396 - learning_rate: 0.0010\n",
      "Epoch 53/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0414 - mae: 0.6380 - val_loss: 0.6364 - val_mae: 0.4084 - learning_rate: 0.0010\n",
      "Epoch 54/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0510 - mae: 0.6445 - val_loss: 0.6848 - val_mae: 0.4656 - learning_rate: 0.0010\n",
      "Epoch 55/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0225 - mae: 0.6334 - val_loss: 0.6744 - val_mae: 0.4501 - learning_rate: 0.0010\n",
      "Epoch 56/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0358 - mae: 0.6459 - val_loss: 0.5951 - val_mae: 0.3923 - learning_rate: 0.0010\n",
      "Epoch 57/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9422 - mae: 0.5893 - val_loss: 0.5817 - val_mae: 0.3863 - learning_rate: 0.0010\n",
      "Epoch 58/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9568 - mae: 0.6129 - val_loss: 0.6539 - val_mae: 0.4615 - learning_rate: 0.0010\n",
      "Epoch 59/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8996 - mae: 0.5918 - val_loss: 0.6255 - val_mae: 0.4442 - learning_rate: 0.0010\n",
      "Epoch 60/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9157 - mae: 0.5972 - val_loss: 0.6090 - val_mae: 0.4410 - learning_rate: 0.0010\n",
      "Epoch 61/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8517 - mae: 0.5699 - val_loss: 0.6025 - val_mae: 0.4347 - learning_rate: 0.0010\n",
      "Epoch 62/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8314 - mae: 0.5639 - val_loss: 0.5456 - val_mae: 0.3831 - learning_rate: 0.0010\n",
      "Epoch 63/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8450 - mae: 0.5746 - val_loss: 0.6131 - val_mae: 0.4529 - learning_rate: 0.0010\n",
      "Epoch 64/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8703 - mae: 0.5967 - val_loss: 0.5538 - val_mae: 0.4109 - learning_rate: 0.0010\n",
      "Epoch 65/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8049 - mae: 0.5576 - val_loss: 0.5308 - val_mae: 0.3939 - learning_rate: 0.0010\n",
      "Epoch 66/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7890 - mae: 0.5575 - val_loss: 0.5119 - val_mae: 0.3805 - learning_rate: 0.0010\n",
      "Epoch 67/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7875 - mae: 0.5654 - val_loss: 0.5248 - val_mae: 0.4050 - learning_rate: 0.0010\n",
      "Epoch 68/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7598 - mae: 0.5481 - val_loss: 0.5200 - val_mae: 0.4046 - learning_rate: 0.0010\n",
      "Epoch 69/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7198 - mae: 0.5250 - val_loss: 0.4784 - val_mae: 0.3711 - learning_rate: 0.0010\n",
      "Epoch 70/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7260 - mae: 0.5260 - val_loss: 0.5043 - val_mae: 0.4026 - learning_rate: 0.0010\n",
      "Epoch 71/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7066 - mae: 0.5180 - val_loss: 0.5167 - val_mae: 0.4151 - learning_rate: 0.0010\n",
      "Epoch 72/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6864 - mae: 0.5188 - val_loss: 0.4795 - val_mae: 0.3933 - learning_rate: 0.0010\n",
      "Epoch 73/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6380 - mae: 0.4937 - val_loss: 0.4868 - val_mae: 0.4159 - learning_rate: 0.0010\n",
      "Epoch 74/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6539 - mae: 0.4997 - val_loss: 0.4336 - val_mae: 0.3698 - learning_rate: 0.0010\n",
      "Epoch 75/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5802 - mae: 0.4589 - val_loss: 0.4068 - val_mae: 0.3421 - learning_rate: 0.0010\n",
      "Epoch 76/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6147 - mae: 0.4875 - val_loss: 0.4233 - val_mae: 0.3703 - learning_rate: 0.0010\n",
      "Epoch 77/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5703 - mae: 0.4601 - val_loss: 0.4075 - val_mae: 0.3574 - learning_rate: 0.0010\n",
      "Epoch 78/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5707 - mae: 0.4621 - val_loss: 0.4364 - val_mae: 0.3915 - learning_rate: 0.0010\n",
      "Epoch 79/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5735 - mae: 0.4647 - val_loss: 0.3757 - val_mae: 0.3292 - learning_rate: 0.0010\n",
      "Epoch 80/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5304 - mae: 0.4480 - val_loss: 0.4150 - val_mae: 0.3840 - learning_rate: 0.0010\n",
      "Epoch 81/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5304 - mae: 0.4501 - val_loss: 0.4247 - val_mae: 0.3978 - learning_rate: 0.0010\n",
      "Epoch 82/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5078 - mae: 0.4376 - val_loss: 0.3772 - val_mae: 0.3507 - learning_rate: 0.0010\n",
      "Epoch 83/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4919 - mae: 0.4308 - val_loss: 0.3793 - val_mae: 0.3580 - learning_rate: 0.0010\n",
      "Epoch 84/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4875 - mae: 0.4332 - val_loss: 0.3663 - val_mae: 0.3523 - learning_rate: 0.0010\n",
      "Epoch 85/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4610 - mae: 0.4147 - val_loss: 0.3325 - val_mae: 0.3258 - learning_rate: 0.0010\n",
      "Epoch 86/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4551 - mae: 0.4145 - val_loss: 0.3391 - val_mae: 0.3357 - learning_rate: 0.0010\n",
      "Epoch 87/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4366 - mae: 0.4000 - val_loss: 0.3087 - val_mae: 0.3077 - learning_rate: 0.0010\n",
      "Epoch 88/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4229 - mae: 0.3982 - val_loss: 0.2991 - val_mae: 0.3015 - learning_rate: 0.0010\n",
      "Epoch 89/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4080 - mae: 0.3885 - val_loss: 0.3085 - val_mae: 0.3227 - learning_rate: 0.0010\n",
      "Epoch 90/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3954 - mae: 0.3826 - val_loss: 0.3050 - val_mae: 0.3248 - learning_rate: 0.0010\n",
      "Epoch 91/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3882 - mae: 0.3770 - val_loss: 0.2972 - val_mae: 0.3192 - learning_rate: 0.0010\n",
      "Epoch 92/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3940 - mae: 0.3907 - val_loss: 0.2949 - val_mae: 0.3186 - learning_rate: 0.0010\n",
      "Epoch 93/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3724 - mae: 0.3725 - val_loss: 0.3051 - val_mae: 0.3305 - learning_rate: 0.0010\n",
      "Epoch 94/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3473 - mae: 0.3543 - val_loss: 0.3033 - val_mae: 0.3339 - learning_rate: 0.0010\n",
      "Epoch 95/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3339 - mae: 0.3442 - val_loss: 0.2621 - val_mae: 0.2985 - learning_rate: 0.0010\n",
      "Epoch 96/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3413 - mae: 0.3538 - val_loss: 0.2608 - val_mae: 0.2945 - learning_rate: 0.0010\n",
      "Epoch 97/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3275 - mae: 0.3483 - val_loss: 0.2510 - val_mae: 0.2895 - learning_rate: 0.0010\n",
      "Epoch 98/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3291 - mae: 0.3475 - val_loss: 0.2620 - val_mae: 0.3026 - learning_rate: 0.0010\n",
      "Epoch 99/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3113 - mae: 0.3448 - val_loss: 0.2527 - val_mae: 0.2957 - learning_rate: 0.0010\n",
      "Epoch 100/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2974 - mae: 0.3358 - val_loss: 0.2363 - val_mae: 0.2844 - learning_rate: 0.0010\n",
      "Epoch 101/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2864 - mae: 0.3247 - val_loss: 0.2287 - val_mae: 0.2791 - learning_rate: 0.0010\n",
      "Epoch 102/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2806 - mae: 0.3238 - val_loss: 0.2144 - val_mae: 0.2705 - learning_rate: 0.0010\n",
      "Epoch 103/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2777 - mae: 0.3188 - val_loss: 0.2116 - val_mae: 0.2686 - learning_rate: 0.0010\n",
      "Epoch 104/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2651 - mae: 0.3146 - val_loss: 0.2062 - val_mae: 0.2671 - learning_rate: 0.0010\n",
      "Epoch 105/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2676 - mae: 0.3207 - val_loss: 0.2137 - val_mae: 0.2821 - learning_rate: 0.0010\n",
      "Epoch 106/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2635 - mae: 0.3134 - val_loss: 0.2388 - val_mae: 0.3069 - learning_rate: 0.0010\n",
      "Epoch 107/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2517 - mae: 0.3091 - val_loss: 0.2105 - val_mae: 0.2854 - learning_rate: 0.0010\n",
      "Epoch 108/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2425 - mae: 0.3067 - val_loss: 0.2256 - val_mae: 0.2992 - learning_rate: 0.0010\n",
      "Epoch 109/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2529 - mae: 0.3192 - val_loss: 0.1993 - val_mae: 0.2789 - learning_rate: 0.0010\n",
      "Epoch 110/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2335 - mae: 0.2939 - val_loss: 0.1940 - val_mae: 0.2710 - learning_rate: 0.0010\n",
      "Epoch 111/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2280 - mae: 0.2922 - val_loss: 0.1882 - val_mae: 0.2698 - learning_rate: 0.0010\n",
      "Epoch 112/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2356 - mae: 0.3098 - val_loss: 0.1889 - val_mae: 0.2777 - learning_rate: 0.0010\n",
      "Epoch 113/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2172 - mae: 0.2891 - val_loss: 0.1710 - val_mae: 0.2519 - learning_rate: 0.0010\n",
      "Epoch 114/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2185 - mae: 0.2871 - val_loss: 0.1734 - val_mae: 0.2590 - learning_rate: 0.0010\n",
      "Epoch 115/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2210 - mae: 0.2951 - val_loss: 0.1778 - val_mae: 0.2653 - learning_rate: 0.0010\n",
      "Epoch 116/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2064 - mae: 0.2815 - val_loss: 0.1707 - val_mae: 0.2616 - learning_rate: 0.0010\n",
      "Epoch 117/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2035 - mae: 0.2848 - val_loss: 0.1613 - val_mae: 0.2517 - learning_rate: 0.0010\n",
      "Epoch 118/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1977 - mae: 0.2783 - val_loss: 0.1561 - val_mae: 0.2479 - learning_rate: 0.0010\n",
      "Epoch 119/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1969 - mae: 0.2827 - val_loss: 0.1595 - val_mae: 0.2506 - learning_rate: 0.0010\n",
      "Epoch 120/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1914 - mae: 0.2763 - val_loss: 0.1584 - val_mae: 0.2595 - learning_rate: 0.0010\n",
      "Epoch 121/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1855 - mae: 0.2721 - val_loss: 0.1577 - val_mae: 0.2591 - learning_rate: 0.0010\n",
      "Epoch 122/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1833 - mae: 0.2723 - val_loss: 0.1472 - val_mae: 0.2472 - learning_rate: 0.0010\n",
      "Epoch 123/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1772 - mae: 0.2672 - val_loss: 0.1348 - val_mae: 0.2262 - learning_rate: 0.0010\n",
      "Epoch 124/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1696 - mae: 0.2637 - val_loss: 0.1358 - val_mae: 0.2314 - learning_rate: 0.0010\n",
      "Epoch 125/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1721 - mae: 0.2699 - val_loss: 0.1278 - val_mae: 0.2209 - learning_rate: 0.0010\n",
      "Epoch 126/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1658 - mae: 0.2610 - val_loss: 0.1285 - val_mae: 0.2274 - learning_rate: 0.0010\n",
      "Epoch 127/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1646 - mae: 0.2617 - val_loss: 0.1343 - val_mae: 0.2375 - learning_rate: 0.0010\n",
      "Epoch 128/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1722 - mae: 0.2717 - val_loss: 0.1305 - val_mae: 0.2417 - learning_rate: 0.0010\n",
      "Epoch 129/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1566 - mae: 0.2542 - val_loss: 0.1337 - val_mae: 0.2435 - learning_rate: 0.0010\n",
      "Epoch 130/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1611 - mae: 0.2611 - val_loss: 0.1328 - val_mae: 0.2507 - learning_rate: 0.0010\n",
      "Epoch 131/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1581 - mae: 0.2605 - val_loss: 0.1212 - val_mae: 0.2275 - learning_rate: 0.0010\n",
      "Epoch 132/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1504 - mae: 0.2574 - val_loss: 0.1166 - val_mae: 0.2232 - learning_rate: 0.0010\n",
      "Epoch 133/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1498 - mae: 0.2596 - val_loss: 0.1109 - val_mae: 0.2117 - learning_rate: 0.0010\n",
      "Epoch 134/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1469 - mae: 0.2555 - val_loss: 0.1042 - val_mae: 0.2043 - learning_rate: 0.0010\n",
      "Epoch 135/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1365 - mae: 0.2446 - val_loss: 0.1054 - val_mae: 0.2090 - learning_rate: 0.0010\n",
      "Epoch 136/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1375 - mae: 0.2451 - val_loss: 0.1046 - val_mae: 0.2067 - learning_rate: 0.0010\n",
      "Epoch 137/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1374 - mae: 0.2457 - val_loss: 0.1075 - val_mae: 0.2178 - learning_rate: 0.0010\n",
      "Epoch 138/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1344 - mae: 0.2456 - val_loss: 0.1049 - val_mae: 0.2137 - learning_rate: 0.0010\n",
      "Epoch 139/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1325 - mae: 0.2430 - val_loss: 0.1018 - val_mae: 0.2060 - learning_rate: 0.0010\n",
      "Epoch 140/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1331 - mae: 0.2440 - val_loss: 0.1026 - val_mae: 0.2138 - learning_rate: 0.0010\n",
      "Epoch 141/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1342 - mae: 0.2456 - val_loss: 0.1025 - val_mae: 0.2179 - learning_rate: 0.0010\n",
      "Epoch 142/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1287 - mae: 0.2428 - val_loss: 0.0971 - val_mae: 0.2030 - learning_rate: 0.0010\n",
      "Epoch 143/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1236 - mae: 0.2364 - val_loss: 0.1024 - val_mae: 0.2158 - learning_rate: 0.0010\n",
      "Epoch 144/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1292 - mae: 0.2456 - val_loss: 0.0983 - val_mae: 0.2197 - learning_rate: 0.0010\n",
      "Epoch 145/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1216 - mae: 0.2378 - val_loss: 0.0933 - val_mae: 0.2065 - learning_rate: 0.0010\n",
      "Epoch 146/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1191 - mae: 0.2327 - val_loss: 0.0948 - val_mae: 0.2068 - learning_rate: 0.0010\n",
      "Epoch 147/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1177 - mae: 0.2354 - val_loss: 0.0940 - val_mae: 0.2121 - learning_rate: 0.0010\n",
      "Epoch 148/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1213 - mae: 0.2373 - val_loss: 0.0968 - val_mae: 0.2171 - learning_rate: 0.0010\n",
      "Epoch 149/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1222 - mae: 0.2412 - val_loss: 0.0907 - val_mae: 0.2097 - learning_rate: 0.0010\n",
      "Epoch 150/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1176 - mae: 0.2367 - val_loss: 0.0876 - val_mae: 0.2013 - learning_rate: 0.0010\n",
      "Epoch 151/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1188 - mae: 0.2428 - val_loss: 0.0980 - val_mae: 0.2262 - learning_rate: 0.0010\n",
      "Epoch 152/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1196 - mae: 0.2396 - val_loss: 0.0973 - val_mae: 0.2224 - learning_rate: 0.0010\n",
      "Epoch 153/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1194 - mae: 0.2407 - val_loss: 0.0965 - val_mae: 0.2227 - learning_rate: 0.0010\n",
      "Epoch 154/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1188 - mae: 0.2397 - val_loss: 0.0885 - val_mae: 0.2028 - learning_rate: 0.0010\n",
      "Epoch 155/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1140 - mae: 0.2365 - val_loss: 0.0886 - val_mae: 0.2086 - learning_rate: 0.0010\n",
      "Epoch 156/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1098 - mae: 0.2342 - val_loss: 0.0991 - val_mae: 0.2267 - learning_rate: 0.0010\n",
      "Epoch 157/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1117 - mae: 0.2304 - val_loss: 0.0881 - val_mae: 0.2142 - learning_rate: 0.0010\n",
      "Epoch 158/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1097 - mae: 0.2310 - val_loss: 0.0879 - val_mae: 0.2123 - learning_rate: 0.0010\n",
      "Epoch 159/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1103 - mae: 0.2340 - val_loss: 0.0875 - val_mae: 0.2148 - learning_rate: 0.0010\n",
      "Epoch 160/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1097 - mae: 0.2337 - val_loss: 0.0910 - val_mae: 0.2230 - learning_rate: 0.0010\n",
      "Epoch 161/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1097 - mae: 0.2318 - val_loss: 0.0863 - val_mae: 0.2124 - learning_rate: 0.0010\n",
      "Epoch 162/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1146 - mae: 0.2369 - val_loss: 0.0902 - val_mae: 0.2256 - learning_rate: 0.0010\n",
      "Epoch 163/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1088 - mae: 0.2331 - val_loss: 0.0880 - val_mae: 0.2187 - learning_rate: 0.0010\n",
      "Epoch 164/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1083 - mae: 0.2336 - val_loss: 0.0878 - val_mae: 0.2146 - learning_rate: 0.0010\n",
      "Epoch 165/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1058 - mae: 0.2305 - val_loss: 0.0906 - val_mae: 0.2229 - learning_rate: 0.0010\n",
      "Epoch 166/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1083 - mae: 0.2336 - val_loss: 0.0855 - val_mae: 0.2164 - learning_rate: 0.0010\n",
      "Epoch 167/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1077 - mae: 0.2344 - val_loss: 0.0827 - val_mae: 0.2071 - learning_rate: 0.0010\n",
      "Epoch 168/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1080 - mae: 0.2329 - val_loss: 0.0909 - val_mae: 0.2199 - learning_rate: 0.0010\n",
      "Epoch 169/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1073 - mae: 0.2342 - val_loss: 0.0861 - val_mae: 0.2200 - learning_rate: 0.0010\n",
      "Epoch 170/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1092 - mae: 0.2327 - val_loss: 0.0838 - val_mae: 0.2133 - learning_rate: 0.0010\n",
      "Epoch 171/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1104 - mae: 0.2373 - val_loss: 0.0829 - val_mae: 0.2102 - learning_rate: 0.0010\n",
      "Epoch 172/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1085 - mae: 0.2352 - val_loss: 0.0846 - val_mae: 0.2164 - learning_rate: 0.0010\n",
      "Epoch 173/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1053 - mae: 0.2296 - val_loss: 0.0812 - val_mae: 0.2024 - learning_rate: 0.0010\n",
      "Epoch 174/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1052 - mae: 0.2314 - val_loss: 0.0815 - val_mae: 0.2113 - learning_rate: 0.0010\n",
      "Epoch 175/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1034 - mae: 0.2291 - val_loss: 0.0804 - val_mae: 0.2071 - learning_rate: 0.0010\n",
      "Epoch 176/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1010 - mae: 0.2288 - val_loss: 0.0860 - val_mae: 0.2098 - learning_rate: 0.0010\n",
      "Epoch 177/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1032 - mae: 0.2316 - val_loss: 0.0822 - val_mae: 0.2025 - learning_rate: 0.0010\n",
      "Epoch 178/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1021 - mae: 0.2280 - val_loss: 0.0789 - val_mae: 0.2046 - learning_rate: 0.0010\n",
      "Epoch 179/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1001 - mae: 0.2262 - val_loss: 0.0813 - val_mae: 0.2125 - learning_rate: 0.0010\n",
      "Epoch 180/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1035 - mae: 0.2320 - val_loss: 0.0817 - val_mae: 0.2104 - learning_rate: 0.0010\n",
      "Epoch 181/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1010 - mae: 0.2262 - val_loss: 0.0830 - val_mae: 0.2150 - learning_rate: 0.0010\n",
      "Epoch 182/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1021 - mae: 0.2281 - val_loss: 0.0787 - val_mae: 0.2055 - learning_rate: 0.0010\n",
      "Epoch 183/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1003 - mae: 0.2282 - val_loss: 0.0805 - val_mae: 0.2022 - learning_rate: 0.0010\n",
      "Epoch 184/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0995 - mae: 0.2256 - val_loss: 0.0963 - val_mae: 0.2265 - learning_rate: 0.0010\n",
      "Epoch 185/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1022 - mae: 0.2298 - val_loss: 0.0811 - val_mae: 0.2073 - learning_rate: 0.0010\n",
      "Epoch 186/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1010 - mae: 0.2259 - val_loss: 0.0825 - val_mae: 0.2110 - learning_rate: 0.0010\n",
      "Epoch 187/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0995 - mae: 0.2263 - val_loss: 0.0790 - val_mae: 0.2088 - learning_rate: 0.0010\n",
      "Epoch 188/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1012 - mae: 0.2290 - val_loss: 0.0789 - val_mae: 0.1990 - learning_rate: 0.0010\n",
      "Epoch 189/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1007 - mae: 0.2288 - val_loss: 0.0906 - val_mae: 0.2133 - learning_rate: 0.0010\n",
      "Epoch 190/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1001 - mae: 0.2259 - val_loss: 0.0828 - val_mae: 0.2113 - learning_rate: 0.0010\n",
      "Epoch 191/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1028 - mae: 0.2301 - val_loss: 0.0809 - val_mae: 0.2048 - learning_rate: 0.0010\n",
      "Epoch 192/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0978 - mae: 0.2244 - val_loss: 0.0796 - val_mae: 0.2071 - learning_rate: 0.0010\n",
      "Epoch 193/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0998 - mae: 0.2280 - val_loss: 0.0786 - val_mae: 0.2050 - learning_rate: 0.0010\n",
      "Epoch 194/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1013 - mae: 0.2305 - val_loss: 0.0796 - val_mae: 0.2100 - learning_rate: 0.0010\n",
      "Epoch 195/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1038 - mae: 0.2337 - val_loss: 0.0822 - val_mae: 0.2164 - learning_rate: 0.0010\n",
      "Epoch 196/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1001 - mae: 0.2284 - val_loss: 0.0795 - val_mae: 0.2044 - learning_rate: 0.0010\n",
      "Epoch 197/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1001 - mae: 0.2288 - val_loss: 0.0802 - val_mae: 0.2071 - learning_rate: 0.0010\n",
      "Epoch 198/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0966 - mae: 0.2259 - val_loss: 0.0869 - val_mae: 0.2191 - learning_rate: 0.0010\n",
      "Epoch 199/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0988 - mae: 0.2267 - val_loss: 0.0790 - val_mae: 0.2078 - learning_rate: 0.0010\n",
      "Epoch 200/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0982 - mae: 0.2275 - val_loss: 0.0799 - val_mae: 0.2060 - learning_rate: 0.0010\n",
      "Epoch 201/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1000 - mae: 0.2290 - val_loss: 0.0773 - val_mae: 0.2051 - learning_rate: 0.0010\n",
      "Epoch 202/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0969 - mae: 0.2254 - val_loss: 0.0762 - val_mae: 0.2042 - learning_rate: 0.0010\n",
      "Epoch 203/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0991 - mae: 0.2311 - val_loss: 0.0765 - val_mae: 0.1996 - learning_rate: 0.0010\n",
      "Epoch 204/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0992 - mae: 0.2285 - val_loss: 0.0782 - val_mae: 0.2057 - learning_rate: 0.0010\n",
      "Epoch 205/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0976 - mae: 0.2256 - val_loss: 0.0782 - val_mae: 0.2009 - learning_rate: 0.0010\n",
      "Epoch 206/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0976 - mae: 0.2259 - val_loss: 0.0823 - val_mae: 0.2122 - learning_rate: 0.0010\n",
      "Epoch 207/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0993 - mae: 0.2304 - val_loss: 0.0772 - val_mae: 0.2051 - learning_rate: 0.0010\n",
      "Epoch 208/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0979 - mae: 0.2248 - val_loss: 0.0796 - val_mae: 0.2132 - learning_rate: 0.0010\n",
      "Epoch 209/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0966 - mae: 0.2228 - val_loss: 0.0782 - val_mae: 0.2176 - learning_rate: 0.0010\n",
      "Epoch 210/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0944 - mae: 0.2219 - val_loss: 0.0778 - val_mae: 0.2111 - learning_rate: 0.0010\n",
      "Epoch 211/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0978 - mae: 0.2273 - val_loss: 0.0796 - val_mae: 0.2132 - learning_rate: 0.0010\n",
      "Epoch 212/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0976 - mae: 0.2289 - val_loss: 0.0757 - val_mae: 0.2050 - learning_rate: 0.0010\n",
      "Epoch 213/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0970 - mae: 0.2268 - val_loss: 0.0770 - val_mae: 0.2034 - learning_rate: 0.0010\n",
      "Epoch 214/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0982 - mae: 0.2300 - val_loss: 0.0754 - val_mae: 0.2068 - learning_rate: 0.0010\n",
      "Epoch 215/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0957 - mae: 0.2251 - val_loss: 0.0785 - val_mae: 0.2154 - learning_rate: 0.0010\n",
      "Epoch 216/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0958 - mae: 0.2235 - val_loss: 0.0788 - val_mae: 0.2122 - learning_rate: 0.0010\n",
      "Epoch 217/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0967 - mae: 0.2244 - val_loss: 0.0768 - val_mae: 0.2120 - learning_rate: 0.0010\n",
      "Epoch 218/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0933 - mae: 0.2239 - val_loss: 0.0778 - val_mae: 0.2111 - learning_rate: 0.0010\n",
      "Epoch 219/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0994 - mae: 0.2320 - val_loss: 0.0752 - val_mae: 0.2062 - learning_rate: 0.0010\n",
      "Epoch 220/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0973 - mae: 0.2274 - val_loss: 0.0784 - val_mae: 0.2098 - learning_rate: 0.0010\n",
      "Epoch 221/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0975 - mae: 0.2259 - val_loss: 0.0753 - val_mae: 0.2020 - learning_rate: 0.0010\n",
      "Epoch 222/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0987 - mae: 0.2288 - val_loss: 0.0769 - val_mae: 0.2053 - learning_rate: 0.0010\n",
      "Epoch 223/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0978 - mae: 0.2271 - val_loss: 0.0784 - val_mae: 0.2163 - learning_rate: 0.0010\n",
      "Epoch 224/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0946 - mae: 0.2240 - val_loss: 0.0756 - val_mae: 0.2028 - learning_rate: 0.0010\n",
      "Epoch 225/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0977 - mae: 0.2273 - val_loss: 0.0799 - val_mae: 0.2086 - learning_rate: 0.0010\n",
      "Epoch 226/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0961 - mae: 0.2253 - val_loss: 0.0826 - val_mae: 0.2220 - learning_rate: 0.0010\n",
      "Epoch 227/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0950 - mae: 0.2230 - val_loss: 0.0864 - val_mae: 0.2329 - learning_rate: 0.0010\n",
      "Epoch 228/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0988 - mae: 0.2306 - val_loss: 0.0760 - val_mae: 0.2109 - learning_rate: 0.0010\n",
      "Epoch 229/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0931 - mae: 0.2250 - val_loss: 0.0771 - val_mae: 0.2038 - learning_rate: 0.0010\n",
      "Epoch 230/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0963 - mae: 0.2274 - val_loss: 0.0741 - val_mae: 0.2034 - learning_rate: 0.0010\n",
      "Epoch 231/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0959 - mae: 0.2296 - val_loss: 0.0768 - val_mae: 0.2128 - learning_rate: 0.0010\n",
      "Epoch 232/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0934 - mae: 0.2255 - val_loss: 0.0749 - val_mae: 0.2052 - learning_rate: 0.0010\n",
      "Epoch 233/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0934 - mae: 0.2247 - val_loss: 0.0781 - val_mae: 0.2152 - learning_rate: 0.0010\n",
      "Epoch 234/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0965 - mae: 0.2295 - val_loss: 0.0757 - val_mae: 0.2067 - learning_rate: 0.0010\n",
      "Epoch 235/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1001 - mae: 0.2361 - val_loss: 0.0775 - val_mae: 0.2134 - learning_rate: 0.0010\n",
      "Epoch 236/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0972 - mae: 0.2283 - val_loss: 0.0766 - val_mae: 0.2128 - learning_rate: 0.0010\n",
      "Epoch 237/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0938 - mae: 0.2288 - val_loss: 0.0776 - val_mae: 0.2149 - learning_rate: 0.0010\n",
      "Epoch 238/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0925 - mae: 0.2253 - val_loss: 0.0778 - val_mae: 0.2096 - learning_rate: 0.0010\n",
      "Epoch 239/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0947 - mae: 0.2274 - val_loss: 0.0778 - val_mae: 0.2125 - learning_rate: 0.0010\n",
      "Epoch 240/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0951 - mae: 0.2276 - val_loss: 0.0763 - val_mae: 0.2071 - learning_rate: 0.0010\n",
      "Epoch 241/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0954 - mae: 0.2288 - val_loss: 0.0764 - val_mae: 0.2007 - learning_rate: 0.0010\n",
      "Epoch 242/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0963 - mae: 0.2268 - val_loss: 0.0817 - val_mae: 0.2164 - learning_rate: 0.0010\n",
      "Epoch 243/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0929 - mae: 0.2249 - val_loss: 0.0755 - val_mae: 0.2065 - learning_rate: 0.0010\n",
      "Epoch 244/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0940 - mae: 0.2259 - val_loss: 0.0782 - val_mae: 0.2191 - learning_rate: 0.0010\n",
      "Epoch 245/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0874 - mae: 0.2186 - val_loss: 0.0775 - val_mae: 0.2064 - learning_rate: 0.0010\n",
      "Epoch 246/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0922 - mae: 0.2207 - val_loss: 0.0773 - val_mae: 0.2147 - learning_rate: 0.0010\n",
      "Epoch 247/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0989 - mae: 0.2327 - val_loss: 0.0785 - val_mae: 0.2206 - learning_rate: 0.0010\n",
      "Epoch 248/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0920 - mae: 0.2223 - val_loss: 0.0759 - val_mae: 0.2082 - learning_rate: 0.0010\n",
      "Epoch 249/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0925 - mae: 0.2254 - val_loss: 0.0736 - val_mae: 0.2120 - learning_rate: 0.0010\n",
      "Epoch 250/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0917 - mae: 0.2231 - val_loss: 0.0775 - val_mae: 0.2175 - learning_rate: 0.0010\n",
      "Epoch 251/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0960 - mae: 0.2325 - val_loss: 0.0743 - val_mae: 0.2066 - learning_rate: 0.0010\n",
      "Epoch 252/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0927 - mae: 0.2226 - val_loss: 0.0808 - val_mae: 0.2221 - learning_rate: 0.0010\n",
      "Epoch 253/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0934 - mae: 0.2250 - val_loss: 0.0869 - val_mae: 0.2343 - learning_rate: 0.0010\n",
      "Epoch 254/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0936 - mae: 0.2265 - val_loss: 0.0790 - val_mae: 0.2176 - learning_rate: 0.0010\n",
      "Epoch 255/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0917 - mae: 0.2234 - val_loss: 0.0753 - val_mae: 0.2058 - learning_rate: 0.0010\n",
      "Epoch 256/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0976 - mae: 0.2290 - val_loss: 0.0797 - val_mae: 0.2071 - learning_rate: 0.0010\n",
      "Epoch 257/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0946 - mae: 0.2272 - val_loss: 0.0774 - val_mae: 0.2114 - learning_rate: 0.0010\n",
      "Epoch 258/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0931 - mae: 0.2267 - val_loss: 0.0797 - val_mae: 0.2069 - learning_rate: 0.0010\n",
      "Epoch 259/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0939 - mae: 0.2265 - val_loss: 0.0754 - val_mae: 0.2132 - learning_rate: 0.0010\n",
      "Epoch 260/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0939 - mae: 0.2269 - val_loss: 0.0738 - val_mae: 0.2080 - learning_rate: 0.0010\n",
      "Epoch 261/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0915 - mae: 0.2208 - val_loss: 0.0774 - val_mae: 0.2127 - learning_rate: 0.0010\n",
      "Epoch 262/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0953 - mae: 0.2267 - val_loss: 0.0789 - val_mae: 0.2239 - learning_rate: 0.0010\n",
      "Epoch 263/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0920 - mae: 0.2245 - val_loss: 0.0762 - val_mae: 0.2127 - learning_rate: 0.0010\n",
      "Epoch 264/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0958 - mae: 0.2285 - val_loss: 0.0754 - val_mae: 0.2094 - learning_rate: 0.0010\n",
      "Epoch 265/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0958 - mae: 0.2256 - val_loss: 0.0741 - val_mae: 0.2118 - learning_rate: 0.0010\n",
      "Epoch 266/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0924 - mae: 0.2257 - val_loss: 0.0750 - val_mae: 0.2142 - learning_rate: 0.0010\n",
      "Epoch 267/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0919 - mae: 0.2268 - val_loss: 0.0750 - val_mae: 0.2165 - learning_rate: 0.0010\n",
      "Epoch 268/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0928 - mae: 0.2247 - val_loss: 0.0721 - val_mae: 0.2058 - learning_rate: 0.0010\n",
      "Epoch 269/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0914 - mae: 0.2225 - val_loss: 0.0746 - val_mae: 0.2037 - learning_rate: 0.0010\n",
      "Epoch 270/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0959 - mae: 0.2295 - val_loss: 0.0752 - val_mae: 0.2094 - learning_rate: 0.0010\n",
      "Epoch 271/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0968 - mae: 0.2289 - val_loss: 0.0714 - val_mae: 0.1955 - learning_rate: 0.0010\n",
      "Epoch 272/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0975 - mae: 0.2338 - val_loss: 0.0726 - val_mae: 0.2040 - learning_rate: 0.0010\n",
      "Epoch 273/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0965 - mae: 0.2319 - val_loss: 0.0735 - val_mae: 0.2082 - learning_rate: 0.0010\n",
      "Epoch 274/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0964 - mae: 0.2300 - val_loss: 0.0764 - val_mae: 0.2121 - learning_rate: 0.0010\n",
      "Epoch 275/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0945 - mae: 0.2271 - val_loss: 0.0739 - val_mae: 0.2029 - learning_rate: 0.0010\n",
      "Epoch 276/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0940 - mae: 0.2270 - val_loss: 0.0768 - val_mae: 0.2134 - learning_rate: 0.0010\n",
      "Epoch 277/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0931 - mae: 0.2287 - val_loss: 0.0736 - val_mae: 0.2111 - learning_rate: 0.0010\n",
      "Epoch 278/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0928 - mae: 0.2273 - val_loss: 0.0768 - val_mae: 0.2144 - learning_rate: 0.0010\n",
      "Epoch 279/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0951 - mae: 0.2281 - val_loss: 0.0743 - val_mae: 0.2099 - learning_rate: 0.0010\n",
      "Epoch 280/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0942 - mae: 0.2265 - val_loss: 0.0816 - val_mae: 0.2114 - learning_rate: 0.0010\n",
      "Epoch 281/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0962 - mae: 0.2286 - val_loss: 0.0838 - val_mae: 0.2229 - learning_rate: 0.0010\n",
      "Epoch 282/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0947 - mae: 0.2287 - val_loss: 0.0752 - val_mae: 0.2097 - learning_rate: 0.0010\n",
      "Epoch 283/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0916 - mae: 0.2223 - val_loss: 0.0793 - val_mae: 0.2179 - learning_rate: 0.0010\n",
      "Epoch 284/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0968 - mae: 0.2320 - val_loss: 0.0746 - val_mae: 0.2043 - learning_rate: 0.0010\n",
      "Epoch 285/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0937 - mae: 0.2275 - val_loss: 0.0751 - val_mae: 0.2084 - learning_rate: 0.0010\n",
      "Epoch 286/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0937 - mae: 0.2282 - val_loss: 0.0764 - val_mae: 0.2166 - learning_rate: 0.0010\n",
      "Epoch 287/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0923 - mae: 0.2281 - val_loss: 0.0720 - val_mae: 0.2043 - learning_rate: 0.0010\n",
      "Epoch 288/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0926 - mae: 0.2251 - val_loss: 0.0736 - val_mae: 0.2111 - learning_rate: 0.0010\n",
      "Epoch 289/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0935 - mae: 0.2284 - val_loss: 0.0728 - val_mae: 0.2104 - learning_rate: 0.0010\n",
      "Epoch 290/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0901 - mae: 0.2206 - val_loss: 0.0744 - val_mae: 0.2135 - learning_rate: 0.0010\n",
      "Epoch 291/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0905 - mae: 0.2236 - val_loss: 0.0718 - val_mae: 0.2042 - learning_rate: 0.0010\n",
      "Epoch 292/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0887 - mae: 0.2211 - val_loss: 0.0751 - val_mae: 0.2111 - learning_rate: 0.0010\n",
      "Epoch 293/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0905 - mae: 0.2235 - val_loss: 0.0754 - val_mae: 0.2127 - learning_rate: 0.0010\n",
      "Epoch 294/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0912 - mae: 0.2238 - val_loss: 0.0733 - val_mae: 0.2090 - learning_rate: 0.0010\n",
      "Epoch 295/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0907 - mae: 0.2239 - val_loss: 0.0722 - val_mae: 0.2047 - learning_rate: 0.0010\n",
      "Epoch 296/400\n",
      "\u001b[1m 1/41\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0637 - mae: 0.2137\n",
      "Epoch 296: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0883 - mae: 0.2199 - val_loss: 0.0740 - val_mae: 0.2019 - learning_rate: 0.0010\n",
      "Epoch 297/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0887 - mae: 0.2212 - val_loss: 0.0720 - val_mae: 0.2048 - learning_rate: 5.0000e-04\n",
      "Epoch 298/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0867 - mae: 0.2184 - val_loss: 0.0718 - val_mae: 0.2051 - learning_rate: 5.0000e-04\n",
      "Epoch 299/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0890 - mae: 0.2196 - val_loss: 0.0705 - val_mae: 0.2026 - learning_rate: 5.0000e-04\n",
      "Epoch 300/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0888 - mae: 0.2223 - val_loss: 0.0693 - val_mae: 0.2037 - learning_rate: 5.0000e-04\n",
      "Epoch 301/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0852 - mae: 0.2154 - val_loss: 0.0713 - val_mae: 0.2085 - learning_rate: 5.0000e-04\n",
      "Epoch 302/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0890 - mae: 0.2232 - val_loss: 0.0722 - val_mae: 0.2079 - learning_rate: 5.0000e-04\n",
      "Epoch 303/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0857 - mae: 0.2191 - val_loss: 0.0727 - val_mae: 0.2063 - learning_rate: 5.0000e-04\n",
      "Epoch 304/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0875 - mae: 0.2187 - val_loss: 0.0735 - val_mae: 0.2091 - learning_rate: 5.0000e-04\n",
      "Epoch 305/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0877 - mae: 0.2187 - val_loss: 0.0756 - val_mae: 0.2161 - learning_rate: 5.0000e-04\n",
      "Epoch 306/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0859 - mae: 0.2193 - val_loss: 0.0729 - val_mae: 0.2030 - learning_rate: 5.0000e-04\n",
      "Epoch 307/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0867 - mae: 0.2201 - val_loss: 0.0731 - val_mae: 0.2068 - learning_rate: 5.0000e-04\n",
      "Epoch 308/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0873 - mae: 0.2207 - val_loss: 0.0715 - val_mae: 0.2072 - learning_rate: 5.0000e-04\n",
      "Epoch 309/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0863 - mae: 0.2201 - val_loss: 0.0714 - val_mae: 0.2048 - learning_rate: 5.0000e-04\n",
      "Epoch 310/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0867 - mae: 0.2197 - val_loss: 0.0698 - val_mae: 0.2062 - learning_rate: 5.0000e-04\n",
      "Epoch 311/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0874 - mae: 0.2195 - val_loss: 0.0710 - val_mae: 0.2064 - learning_rate: 5.0000e-04\n",
      "Epoch 312/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0855 - mae: 0.2158 - val_loss: 0.0700 - val_mae: 0.2018 - learning_rate: 5.0000e-04\n",
      "Epoch 313/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0845 - mae: 0.2151 - val_loss: 0.0732 - val_mae: 0.2066 - learning_rate: 5.0000e-04\n",
      "Epoch 314/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0910 - mae: 0.2264 - val_loss: 0.0748 - val_mae: 0.2144 - learning_rate: 5.0000e-04\n",
      "Epoch 315/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0853 - mae: 0.2166 - val_loss: 0.0727 - val_mae: 0.2089 - learning_rate: 5.0000e-04\n",
      "Epoch 316/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0877 - mae: 0.2224 - val_loss: 0.0725 - val_mae: 0.2111 - learning_rate: 5.0000e-04\n",
      "Epoch 317/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0886 - mae: 0.2200 - val_loss: 0.0732 - val_mae: 0.2112 - learning_rate: 5.0000e-04\n",
      "Epoch 318/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0879 - mae: 0.2214 - val_loss: 0.0732 - val_mae: 0.2106 - learning_rate: 5.0000e-04\n",
      "Epoch 319/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0856 - mae: 0.2190 - val_loss: 0.0741 - val_mae: 0.2174 - learning_rate: 5.0000e-04\n",
      "Epoch 320/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0852 - mae: 0.2171 - val_loss: 0.0728 - val_mae: 0.2083 - learning_rate: 5.0000e-04\n",
      "Epoch 321/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0832 - mae: 0.2131 - val_loss: 0.0726 - val_mae: 0.2071 - learning_rate: 5.0000e-04\n",
      "Epoch 322/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0843 - mae: 0.2138 - val_loss: 0.0710 - val_mae: 0.2048 - learning_rate: 5.0000e-04\n",
      "Epoch 323/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0866 - mae: 0.2188 - val_loss: 0.0716 - val_mae: 0.2027 - learning_rate: 5.0000e-04\n",
      "Epoch 324/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0861 - mae: 0.2165 - val_loss: 0.0755 - val_mae: 0.2111 - learning_rate: 5.0000e-04\n",
      "Epoch 325/400\n",
      "\u001b[1m 1/41\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0892 - mae: 0.2195\n",
      "Epoch 325: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0860 - mae: 0.2185 - val_loss: 0.0718 - val_mae: 0.2056 - learning_rate: 5.0000e-04\n",
      "Epoch 326/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0852 - mae: 0.2169 - val_loss: 0.0718 - val_mae: 0.2063 - learning_rate: 2.5000e-04\n",
      "Epoch 327/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0823 - mae: 0.2136 - val_loss: 0.0720 - val_mae: 0.2044 - learning_rate: 2.5000e-04\n",
      "Epoch 328/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0807 - mae: 0.2099 - val_loss: 0.0714 - val_mae: 0.2014 - learning_rate: 2.5000e-04\n",
      "Epoch 329/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0818 - mae: 0.2138 - val_loss: 0.0700 - val_mae: 0.2019 - learning_rate: 2.5000e-04\n",
      "Epoch 330/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0813 - mae: 0.2123 - val_loss: 0.0700 - val_mae: 0.2029 - learning_rate: 2.5000e-04\n",
      "Epoch 331/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0840 - mae: 0.2142 - val_loss: 0.0709 - val_mae: 0.2062 - learning_rate: 2.5000e-04\n",
      "Epoch 332/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0809 - mae: 0.2122 - val_loss: 0.0703 - val_mae: 0.2042 - learning_rate: 2.5000e-04\n",
      "Epoch 333/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0819 - mae: 0.2110 - val_loss: 0.0704 - val_mae: 0.2056 - learning_rate: 2.5000e-04\n",
      "Epoch 334/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0835 - mae: 0.2156 - val_loss: 0.0712 - val_mae: 0.2053 - learning_rate: 2.5000e-04\n",
      "Epoch 335/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0818 - mae: 0.2120 - val_loss: 0.0706 - val_mae: 0.2044 - learning_rate: 2.5000e-04\n",
      "Epoch 336/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0822 - mae: 0.2131 - val_loss: 0.0712 - val_mae: 0.2087 - learning_rate: 2.5000e-04\n",
      "Epoch 337/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0815 - mae: 0.2111 - val_loss: 0.0717 - val_mae: 0.2109 - learning_rate: 2.5000e-04\n",
      "Epoch 338/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0846 - mae: 0.2164 - val_loss: 0.0707 - val_mae: 0.2041 - learning_rate: 2.5000e-04\n",
      "Epoch 339/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0809 - mae: 0.2107 - val_loss: 0.0712 - val_mae: 0.2066 - learning_rate: 2.5000e-04\n",
      "Epoch 340/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0814 - mae: 0.2124 - val_loss: 0.0721 - val_mae: 0.2094 - learning_rate: 2.5000e-04\n",
      "Epoch 341/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0821 - mae: 0.2121 - val_loss: 0.0700 - val_mae: 0.2053 - learning_rate: 2.5000e-04\n",
      "Epoch 342/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0844 - mae: 0.2148 - val_loss: 0.0695 - val_mae: 0.2064 - learning_rate: 2.5000e-04\n",
      "Epoch 343/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0803 - mae: 0.2108 - val_loss: 0.0709 - val_mae: 0.2068 - learning_rate: 2.5000e-04\n",
      "Epoch 344/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0828 - mae: 0.2139 - val_loss: 0.0722 - val_mae: 0.2085 - learning_rate: 2.5000e-04\n",
      "Epoch 345/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0817 - mae: 0.2111 - val_loss: 0.0707 - val_mae: 0.2074 - learning_rate: 2.5000e-04\n",
      "Epoch 346/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0829 - mae: 0.2148 - val_loss: 0.0721 - val_mae: 0.2081 - learning_rate: 2.5000e-04\n",
      "Epoch 347/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0821 - mae: 0.2163 - val_loss: 0.0726 - val_mae: 0.2091 - learning_rate: 2.5000e-04\n",
      "Epoch 348/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0818 - mae: 0.2126 - val_loss: 0.0720 - val_mae: 0.2080 - learning_rate: 2.5000e-04\n",
      "Epoch 349/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0815 - mae: 0.2112 - val_loss: 0.0699 - val_mae: 0.2028 - learning_rate: 2.5000e-04\n",
      "Epoch 350/400\n",
      "\u001b[1m 1/41\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0441 - mae: 0.1708\n",
      "Epoch 350: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0796 - mae: 0.2104 - val_loss: 0.0704 - val_mae: 0.2068 - learning_rate: 2.5000e-04\n",
      "Epoch 351/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0793 - mae: 0.2095 - val_loss: 0.0707 - val_mae: 0.2047 - learning_rate: 1.2500e-04\n",
      "Epoch 352/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0822 - mae: 0.2115 - val_loss: 0.0709 - val_mae: 0.2066 - learning_rate: 1.2500e-04\n",
      "Epoch 353/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0823 - mae: 0.2127 - val_loss: 0.0703 - val_mae: 0.2046 - learning_rate: 1.2500e-04\n",
      "Epoch 354/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0787 - mae: 0.2079 - val_loss: 0.0705 - val_mae: 0.2046 - learning_rate: 1.2500e-04\n",
      "Epoch 355/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0788 - mae: 0.2104 - val_loss: 0.0710 - val_mae: 0.2054 - learning_rate: 1.2500e-04\n",
      "Epoch 356/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0804 - mae: 0.2104 - val_loss: 0.0717 - val_mae: 0.2067 - learning_rate: 1.2500e-04\n",
      "Epoch 357/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0782 - mae: 0.2065 - val_loss: 0.0723 - val_mae: 0.2082 - learning_rate: 1.2500e-04\n",
      "Epoch 358/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0790 - mae: 0.2079 - val_loss: 0.0721 - val_mae: 0.2078 - learning_rate: 1.2500e-04\n",
      "Epoch 359/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0795 - mae: 0.2104 - val_loss: 0.0719 - val_mae: 0.2080 - learning_rate: 1.2500e-04\n",
      "Epoch 360/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0802 - mae: 0.2105 - val_loss: 0.0710 - val_mae: 0.2057 - learning_rate: 1.2500e-04\n",
      "Epoch 361/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0807 - mae: 0.2110 - val_loss: 0.0712 - val_mae: 0.2059 - learning_rate: 1.2500e-04\n",
      "Epoch 362/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0780 - mae: 0.2087 - val_loss: 0.0713 - val_mae: 0.2060 - learning_rate: 1.2500e-04\n",
      "Epoch 363/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0797 - mae: 0.2086 - val_loss: 0.0717 - val_mae: 0.2070 - learning_rate: 1.2500e-04\n",
      "Epoch 364/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0789 - mae: 0.2091 - val_loss: 0.0731 - val_mae: 0.2096 - learning_rate: 1.2500e-04\n",
      "Epoch 365/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0776 - mae: 0.2078 - val_loss: 0.0729 - val_mae: 0.2084 - learning_rate: 1.2500e-04\n",
      "Epoch 366/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0779 - mae: 0.2060 - val_loss: 0.0730 - val_mae: 0.2091 - learning_rate: 1.2500e-04\n",
      "Epoch 367/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0759 - mae: 0.2041 - val_loss: 0.0726 - val_mae: 0.2090 - learning_rate: 1.2500e-04\n",
      "Epoch 368/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0797 - mae: 0.2087 - val_loss: 0.0727 - val_mae: 0.2086 - learning_rate: 1.2500e-04\n",
      "Epoch 369/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0771 - mae: 0.2061 - val_loss: 0.0713 - val_mae: 0.2065 - learning_rate: 1.2500e-04\n",
      "Epoch 370/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0776 - mae: 0.2067 - val_loss: 0.0716 - val_mae: 0.2053 - learning_rate: 1.2500e-04\n",
      "Epoch 371/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0776 - mae: 0.2059 - val_loss: 0.0716 - val_mae: 0.2056 - learning_rate: 1.2500e-04\n",
      "Epoch 372/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0788 - mae: 0.2067 - val_loss: 0.0708 - val_mae: 0.2065 - learning_rate: 1.2500e-04\n",
      "Epoch 373/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0778 - mae: 0.2057 - val_loss: 0.0718 - val_mae: 0.2080 - learning_rate: 1.2500e-04\n",
      "Epoch 374/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0785 - mae: 0.2088 - val_loss: 0.0717 - val_mae: 0.2076 - learning_rate: 1.2500e-04\n",
      "Epoch 375/400\n",
      "\u001b[1m 1/41\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1213 - mae: 0.2747\n",
      "Epoch 375: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0788 - mae: 0.2081 - val_loss: 0.0706 - val_mae: 0.2055 - learning_rate: 1.2500e-04\n",
      "Epoch 376/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0769 - mae: 0.2063 - val_loss: 0.0704 - val_mae: 0.2040 - learning_rate: 6.2500e-05\n",
      "Epoch 377/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0799 - mae: 0.2094 - val_loss: 0.0710 - val_mae: 0.2052 - learning_rate: 6.2500e-05\n",
      "Epoch 378/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0789 - mae: 0.2068 - val_loss: 0.0709 - val_mae: 0.2052 - learning_rate: 6.2500e-05\n",
      "Epoch 379/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0765 - mae: 0.2078 - val_loss: 0.0712 - val_mae: 0.2049 - learning_rate: 6.2500e-05\n",
      "Epoch 380/400\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0761 - mae: 0.2044 - val_loss: 0.0704 - val_mae: 0.2036 - learning_rate: 6.2500e-05\n",
      "Epoch 380: early stopping\n",
      "Restoring model weights from the end of the best epoch: 300.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=400,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02609d6-db70-4422-a06b-7f6b9807170c",
   "metadata": {},
   "source": [
    "## Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96db783d-ab4b-4bd1-acf7-1da4b2a61752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['mae'], label='Train MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80bdc00-bb2e-48f2-9357-a9c123d2f446",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "925c9ea9-2f9e-4da2-9517-13b599052780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "MSE на тестовой выборке: 45076.59\n",
      "RMSE на тестовой выборке: 212.31\n",
      "Средний процент ошибки: 24.08%\n",
      "MAE на тестовой выборке: 174.85\n",
      "R² Score: 0.2091\n"
     ]
    }
   ],
   "source": [
    "y_pred_log = model.predict(X_test)\n",
    "\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "y_test_original = np.expm1(y_test)\n",
    "\n",
    "mse = mean_squared_error(y_test_original, y_pred)\n",
    "print(f\"MSE на тестовой выборке: {mse:.2f}\")\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"RMSE на тестовой выборке: {rmse:.2f}\")\n",
    "\n",
    "mean_price = y_test_original.mean()\n",
    "percentage_error = (rmse / mean_price) * 100\n",
    "print(f\"Средний процент ошибки: {percentage_error:.2f}%\")\n",
    "\n",
    "mae = mean_absolute_error(y_test_original, y_pred)\n",
    "print(f\"MAE на тестовой выборке: {mae:.2f}\")\n",
    "\n",
    "r2 = r2_score(y_test_original, y_pred)\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c25aeabf-8980-4da0-aff7-7314ce371015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 22.04%\n"
     ]
    }
   ],
   "source": [
    "mape = mean_absolute_percentage_error(y_test_original, y_pred) * 100\n",
    "print(f\"MAPE: {mape:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv_nn)",
   "language": "python",
   "name": "venv_nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
